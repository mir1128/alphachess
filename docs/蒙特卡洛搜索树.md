# 通过Tic-Toc-Tae理解蒙特卡洛搜索树



### 井字棋棋盘设计以及走子规则

首先需要定义棋盘，设计棋盘的接口如下：

```python
class Board():
    def __init__(self, board=None):
        pass

    def init_board(self):
        pass
    
    def make_move(self):
        pass
    
    def is_draw(self):
        pass
    
    def is_win(self):
        pass
    
    def generate_states(self):
        pass
    
    def game_loop(self):
        pass
        
```



可以定义一个新的棋盘，也可以复制现有的棋盘（以便继续走子）

```python
    def __init__(self, board=None):
        # x 先走， o 后走， .表示空白
        self.player_1 = 'x'
        self.player_2 = 'o'
        self.empty_square = '.'
        
        # 用一个字典表示每个棋子的位置 
        self.position = {}
        
        # 初始化棋盘
        self.init_board()
        
        # 如果之前有棋盘，就深度拷贝原来的
        if board is not None:
            self.__dict__ = deepcopy(board.__dict__)
```



```python
    # 定义一个干净的棋盘
    def init_board(self):
        for row in range(3):
            for col in range(3):
                self.position[row, col] = self.empty_square
   
```



走子逻辑设计很特别，在直觉里，我们会设置当前轮到谁走子，比如用current_player这样的变量记录当前轮到谁走，而这个实现里用player_1记录当前轮到谁，而player_2记录了上一步是谁，很巧妙

```python
    def make_move(self, row, col):
        # 基于当前状态新建一个棋盘
        board = Board(self)
        
        # 每次都是player_1走子，player_1实际上相当于一个占位符，每次走完会互换x和o，这样player_1就记录
        # 了接下来该谁走子,同理，player_2就记录上一步是谁走子
        board.position[row, col] = self.player_1
        
        # 每次走完互换player_1和player_2
        (board.player_1, board.player_2) = (board.player_2, board.player_1)
    
        # 返回新的状态
        return board
```

其他方法省略...

```python
    def is_draw(self):
        pass
	def is_win(self):
        pass
    def generate_states(self):
        pass
    def game_loop(self):
        pass
```



### 蒙特卡洛搜索树设计



蒙特卡洛搜索树(Monte-Carlo Tree Search），以下简称mcts，它的主要作用是帮助找到最佳走法，直观上理解它的接口就是：

```python
class mcts():
    def search(self, board):
        ......
        return next_best_board
```



next_best_board是指**选择了最佳走法的下一个board的状态**，当然也可以返回最佳走法的坐标



#### 蒙特卡洛方法

为了说清楚蒙特卡洛搜索树，首先得了解什么是蒙特卡洛方法。一个经典的蒙特卡洛方法例子是计算圆周率$π$，

具体过程如下：

> 在一个单位正方内画一个内接圆，然后生成随机点，这些随机点有的落入圆内，有的落在圆外（但是在正方形内），生成了足够多的随机点以后，通过计算圆内点数与总随机次数就可以近似得到π
>



![image-20230618233034198](C:\Users\xinxin\AppData\Roaming\Typora\typora-user-images\image-20230618233034198.png)

基本原理是用点的数量来近似表示面积。假设正方形边长为2， 那么内接圆面积就为π，园内点数与总点数之比为$$π/2$$

可见蒙特卡洛方法是用一种暴力模拟的方式来找到近似解的方法。



蒙特卡洛搜索树也是类似的思路，它主要用在对弈类的场景里，想象一下这样的场景：

假设你在和一个高手对弈，你走了一步，然后对面的高手在很短的时间里把接下来若干可能的走法都在头脑中模拟了一遍，这些可能的走法中有的获胜可能性很大，有的获胜可能性很小，然后他当然会选择获胜可能性最大的走法回应你。基本原理就是这么简单，接下来关键就是怎么模拟。



我么知道，下棋的过程实际上是一棵树，棋局从开始到结束就是在沿着这棵树的根到叶子节点的一个过程，叶子节点代表了最终的结果，有可能是一方胜利，另一方失败，也可能是平局。



那么直观的方法就是从当前状态开始，把所有的可能走法都模拟一遍，然后找到基于当前状态下，下一步的最优走法。这里最优走法的定义是指**当前状态下某个子节点所覆盖的所有叶子节点中获胜节点与总节点比值最大的那个**

如果能做到这样当然最好，如果能模拟所有可能，那么就已经立于不败之地。假设从开局第一步就把所有可能都模拟出来，那么结局至少是平局（除非这种棋的本质上是谁先走谁输）



但是棋类变化可能性非常大，例如围棋的变化大概是$$361!$$，这个数字比宇宙中原子的总和还多，即使最先进的计算机也无法全部模拟。因此需要“**有选择性**”的进行模拟，所谓的**有选择性**，就是选择最可能获胜的招数进行模拟。



因此蒙特卡洛搜索树算法结构如下



```python
class mcts():
    def search(self, board):
        for i in range(10000): //进行10000次模拟
        	//对当前状态的所有可能走法中，选择一个分支进行模拟
            //
            
		next_best_board = get_best_move() //选择最佳走法
        return next_best_board
```



从以上算法结构可以看出，算法的关键



蒙特卡洛搜索树的思路类似于多臂老虎机，多臂老虎机是说假设有若干台老虎机，每次摇动老虎机的手臂就会获得一定的奖励，只是不同老虎机奖励不同。如果我们想在固定次数内摇动老虎机并且获得最大的奖励，那么选择摇那一台就是一件值得思考的事情了。



我们不妨从直觉出发，想象一下如果我们此刻站在游戏厅的老虎机前面，我们会做怎样的选择。假设你随机摇了三台，奖励分别是1,2,3，那么接下来你可能一直摇奖励为3的那台，也可能想尝试更多的老虎机，也许能遇到奖励为300的老虎机呢。所以就要面临一个选择难题，是继续摇当前已经知道价值最大的老虎机，还是选择“未知”的老虎机？

**UCB**(Upper Confidence Bound)函数就是为解决这个问题而提出的一个方法，它把所有选择的总价值描述为两部分：对已知进行的持续开发exploitation 以及对未知的探索exploration 



最常用的$UCB1$函数表示如下:


$$
UCB1 = \frac{X_i}{N_i} + c \sqrt{\frac{2 \ln N}{N_i}}
$$



公式由两部分组成其中 $$\frac{X_i}{N_i}$$部分表示exploitation(对已知的的继续开发)，其中$X_i$表示搜索树上的节点$i$的价值，$N_i$表示节点$i$被访问的总次数，因此这一部分很好理解，它的含义表示该节点的平均价值。



公式的后半部分：$$c \sqrt{\frac{2 \ln N}{N_i}}$$表示exploration (对未知的探索)

这个公式的直观解释是：

- `N` 代表父节点的总访问次数。随着父节点的访问次数增加，`ln(N)` 会增加，但增长速度会逐渐减缓。这意味着随着时间的推移，我们越来越倾向于利用已知手臂，而不是继续探索。
- `N_i` 代表当前节点的访问次数。当一个节点被访问得越多，它的不确定性就越小。这意味着我们应该更多地关注那些访问次数较少的节点，以便更好地了解它们的潜在价值。



#### 用一个例子来理解搜索树

蒙特卡洛搜索树首先是一颗博弈树，博弈树的每一层节点代表了一方玩家所有可能的选择，而相邻的层则代表了对方玩家的选择，在对弈时，玩家通常都会选择对自己最为有利的走法，既然是对自己最为有利，那么也就意味着对于对手最为不利，所以如果对于玩家1，如果某一步的评分为$v$，那么对于玩家2这一步评分通常设置为$-v$. 值得说明的是评分为正值和负值只是一种选择，没有偏向性。作为玩家1只要选择正值最大的走法即可，而作为玩家2只要选择负值最小的走法即可。



我们可以观察$UCB1$函数，只有exploitation部分$$\frac{X_i}{N_i}$$包含当前局面的评分，$X_i$是对之前所有模拟获得的分数之和，对于玩家1，这个值是正的，对于玩家2，这个值是负的。而第二部分$$c \sqrt{\frac{2 \ln N}{N_i}}$$对于两个玩家都是一样的，如果$c$取正，那么exploration 永远是正数，因此这对于玩家2逻辑上是错的。



而解决这个问题的方法很简单，我们可以用一个变量跟exploitation部分取值相乘


$$
side= \begin{cases}
1,\quad   &玩家1 \\
-1,\quad  &玩家2
\end{cases}
$$


然后$UCB1$函数就变成了：


$$
UCB1 = side*\frac{X_i}{N_i} + c \sqrt{\frac{2 \ln N}{N_i}}
$$
这样无论对于玩家1还是玩家2，$UCB1$的结果都是正数，编码的时候只要每层都选则最大的正数节点就可以了。



#### 蒙特卡洛搜索树的实现



蒙特卡洛搜索树算法的主要流程如下：



```python
class mcts():
    def search(self, initial_state):
        
        //初始状态
        self.root = TreeNode(initial_state, None)
        
        for i in range(10000): //进行10000次模拟
        
        	//根据UCB1函数找到某个叶子节点
        	node = select(self.root)
            
            //对这个叶子节点进行模拟（如果这个叶子节点已经是游戏的终局，直接返回分数
            //如果不是终局，则进行模拟，根据模拟的最终结果返回分数）
            score = self.rollout(node.board)
            
            //根据模拟的分数，更新该叶子节点所有父节点的访问次数和分数
            self.backpropagate(node, score)
            
		//根据模拟的结果选择最佳走法
		next_best_board = get_best_move()
        return next_best_board
```



理解蒙特卡洛搜索树算法的流程至关重要。有几个关键点需要提示一下：



1. select方法需要一直找到某个叶子节点，然后再进行模拟（非终局节点）或者直接返回结果（终局节点）
2. select方法根据UCB1函数来决定向下选择哪个节点前进，所以在每一层都会调用UCB1函数
3. 选择到叶子节点以后开始rollout模拟，随机模拟的效果一般，alpha zero采用神经网络进行模拟，因此训练神经网络就是棋力的关键
4. 在得到模拟结果以后需要反向更新叶子节点所有的父节点。因为父节点的访问次数和分数都被更新，才导致UCB1方法再执行的时候取值会发生变化，让exploitation 和exploration 产生动态调整，可以说UCB1函数体现了策略



接下来分析每一步的具体实现。蒙特卡洛搜索树分为选择(select)、扩展(expansion)、模拟(rollout)、回溯（backpropagation）,在上面介绍的流程中，扩展被放到选择中了。























